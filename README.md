A video calling web app made using react.js and webrtc.
speech and gesture recognition will be implemented in next build.

1. Project overview

This project is catered towards people having disabilities which makes it hard for them to communicate via traditional video calling.

The app  will use a ML model to recognize hand gestures and convert them and send to the
receiver.

MuteChat is a web application made for video calling and texting but offers additional ways of communicating using hand gestures and speech recognition.

2. Purpose of project 

In today’s world, there are a variety of communication apps using different modes of communication but there are negligible apps catered for mute or deaf people.
MuteChat aims to fix this by introducing ML to traditional video calling.
The ML model will be trained for recognizing hand gestures and converting and sending them  as text.
This will help people with speaking difficulties to communicate with far less hassles.

There will also be a speech recognition model for people with hearing difficulties.
This will convert speech of remote user into text and display on respective user’s display.

3. Modules 
    3.1 Login/Signup
           Authentication using firebase
    3.2 Contacts
           Database storing contacts of user
    3.3 Video calling
           Peer to peer video calling using webRTC
    3.4 Texting        
            Peer to peer texting using webRTC
    3.5 Hand gesture recognition 
           ML model to convert hand gestures into sign language
    3.6 Speech recognition
           ML model to convert speech into text
  3.7 Notification
         Notification service using twilio


https://rakshit-bhardwaj.github.io/mute-chat/
